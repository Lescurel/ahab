{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ahab","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"ljB_ZPLluTsl","colab_type":"code","outputId":"9bcdbe96-3793-4886-c577-cf38433c024a","executionInfo":{"status":"ok","timestamp":1548529521836,"user_tz":-60,"elapsed":23522,"user":{"displayName":"Louis Klein","photoUrl":"https://lh5.googleusercontent.com/--yb8CjO50D4/AAAAAAAAAAI/AAAAAAAAAB8/TCyiFlZhGzY/s64/photo.jpg","userId":"00243407235886690529"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')\n","\n","import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.layers import LSTM, Dense, Activation, Input\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n","from itertools import islice\n","\n","\n","def window(seq, n=2):\n","    \"Returns a sliding window (of width n) over data from the iterable\"\n","    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n","    it = iter(seq)\n","    result = list(islice(it, n))\n","    if len(result) == n:\n","        yield np.array(result)\n","    for elem in it:\n","        result = result[1:] + [elem]\n","        yield np.array(result)\n","\n","def generate_data(txt='mobydick.txt', sliding_win=10):\n","    with open(txt, 'r') as myfile:\n","        data = myfile.read()\n","        tokenizer = Tokenizer(filters=None, lower=False, char_level=True)\n","        tokenizer.fit_on_texts(data);\n","        # dump the word-index correspondance\n","        np.save(\"/content/drive/My Drive/Colab Notebooks/wordindex.npy\", tokenizer.index_word)\n","        seq = tokenizer.texts_to_sequences(data)\n","        # flatten\n","        seq = [i for sub in seq for i in sub]\n","        # prepend data with oov_token (might use 0)\n","        oov = max(tokenizer.word_index.values()) + 1\n","        seq = (sliding_win-1)*[oov]+seq\n","        # labels\n","        y = seq[sliding_win:]  \n","        X = window(seq, sliding_win)\n","        X = np.array(list(X)[:-1])\n","        X = X.reshape((*X.shape, 1))\n","        return X, y\n","\n","def create_model(n_outputs, blocks=2, timesteps=10):\n","    model = Sequential()\n","    model.add(LSTM(16, return_sequences=True, input_shape=(timesteps, 1)))\n","    for _ in range(blocks-1):\n","        model.add(LSTM(16, return_sequences=True))\n","    model.add(LSTM(16))\n","    model.add(Dense(n_outputs))\n","    model.add(Activation('softmax'))\n","    return model\n","\n","def main():\n","    sliding_window = 20\n","    X, y = generate_data(\"/content/drive/My Drive/Colab Notebooks/mobydick.txt\", sliding_win=sliding_window)\n","    model = create_model(max(y)+1, timesteps=sliding_window)\n","    log = CSVLogger(\"/content/drive/My Drive/Colab Notebooks/log_20.csv\")\n","    ckpt = ModelCheckpoint(\"/content/drive/My Drive/Colab Notebooks/best_ahab_20.h5\",\n","                            monitor='acc',\n","                            verbose=0,\n","                            save_best_only=True,\n","                            save_weights_only=False,\n","                            mode='auto',\n","                            period=1)\n","    model.compile(loss = 'sparse_categorical_crossentropy',\n","                  optimizer = 'adam',\n","                  metrics = ['accuracy'])\n","    model.fit(X, y, epochs=80, batch_size=256, callbacks=[log, ckpt])\n","    model.save(\"/content/drive/My Drive/Colab Notebooks/b20_80.h5\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n","Epoch 1/80\n"," 221696/1215235 [====>.........................] - ETA: 10:33 - loss: 3.1676 - acc: 0.1674"],"name":"stdout"}]}]}